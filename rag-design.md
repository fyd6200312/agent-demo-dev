# 金融 RAG 设计方案

## 项目背景

本系统是一个面向金融研报的智能问答系统，核心技术是 RAG（检索增强生成）。系统处理的数据包括券商研报正文、财务报表、结构化数据等，目标是让用户通过自然语言提问，获得准确的金融分析回答。

---

## 业务概览（给非技术读者）

> 如果你是产品经理、业务负责人或决策者，只需要阅读本节。技术细节可以跳过。

### 这个系统能做什么？

**一句话**：让用户用自然语言向研报库提问，系统自动找到相关内容并生成回答。

**具体能力**：

| 问题类型 | 示例 | 系统如何处理 |
|---------|------|-------------|
| 公司分析 | "腾讯Q3游戏业务表现怎么样？" | 从研报中找到腾讯游戏相关段落，总结回答 |
| 产业链梳理 | "光伏产业链上下游有哪些公司？" | 自动识别产业链关系，给出完整图景 |
| 历史规律 | "历史上加息周期银行板块怎么表现？" | 跨多份研报归纳历史规律 |
| 精确数值 | "茅台2024年营收多少？" | 从财务数据库精确查询，不依赖文本 |
| 对比分析 | "宁德时代和比亚迪电池业务有什么区别？" | 找到两家公司相关内容，对比回答 |
| 因果推理 | "猪周期拐点会影响哪些板块？" | 识别因果链条，给出传导路径 |

### 系统不能做什么？

| 限制 | 原因 |
|------|------|
| 不能预测股价 | 系统是信息检索工具，不是预测模型 |
| 不能保证100%准确 | AI生成内容可能有偏差，需人工复核 |
| 不能回答研报库里没有的内容 | "垃圾进，垃圾出"——数据质量决定回答质量 |
| 实时行情需要额外接入 | 当前设计聚焦研报分析，行情数据需单独对接 |

### 典型使用场景

**场景 1：研究员晨会准备**
> 研究员早上问："昨天有哪些公司发了重要公告？对相关板块有什么影响？"
> 系统从公告库和研报库中检索，自动归纳要点。

**场景 2：投资经理快速调研**
> 投资经理问："消费电子产业链最近有什么变化？哪些公司受益？"
> 系统识别产业链关系，从多份研报中提取关键观点。

**场景 3：客户服务答疑**
> 客户问："你们对新能源车行业怎么看？"
> 系统从研报库中找到相关分析，生成结构化回答。

**场景 4：合规检查辅助**
> 合规人员问："最近有哪些研报提到了XX公司的风险因素？"
> 系统定向检索风险相关内容，列出来源。

### 为什么要用"三路召回"架构？

用一个比喻来解释：

| 检索方式 | 比喻 | 擅长 |
|---------|------|------|
| ES（关键词检索） | 图书馆的索引卡片 | 精确查找"茅台2024年报" |
| 向量检索 | 图书管理员的经验 | 理解"白酒龙头"其实是在问茅台 |
| 图谱检索 | 百科全书的关联词条 | 知道光伏产业链包含哪些公司、它们是什么关系 |

三种方式各有所长，组合使用才能覆盖各类问题。

### 投入与产出

**投入估算**（仅供参考，实际因团队和基础设施而异）：

| 阶段 | 周期 | 人力 | 主要工作 |
|------|------|------|---------|
| 阶段一：双路召回（ES+向量） | 4-6周 | 2-3人 | 基础检索能力上线 |
| 阶段二：图谱离线分析 | 4-8周 | 2-3人 | 产业链图谱、板块关联报告 |
| 阶段三：三路实时融合 | 6-10周 | 3-4人 | 完整能力上线 |

**预期产出**：
- 研究员信息检索效率提升 3-5 倍
- 标准化问题可由系统直接回答，减少重复劳动
- 产业链和历史规律分析从"人工梳理"变成"系统辅助"

### 业务人员阅读指引

| 你关心的问题 | 阅读章节 |
|-------------|---------|
| 系统整体架构长什么样？ | 第 8.3 节（系统级检索架构） |
| 为什么选 LightRAG 而不是 GraphRAG？ | 第 1.6 节（方案选择矩阵）、第 1.8 节（结论） |
| 图谱能解决什么问题？ | 第 1.4 节（GraphRAG 的核心优势场景） |
| 金融场景有什么特殊挑战？ | 第 1.5 节（金融场景特殊考量） |
| 三路架构怎么落地？ | 第 10.4 节（三路召回架构） |
| 系统处理哪些数据？ | 第 6 节（RAG 内容选择策略） |

---

## 文档导读

本文档分为三部分：

- **业务概览** — 面向非技术读者（产品经理、业务负责人），用业务语言解释系统能做什么、典型场景、投入产出。**业务人员只需阅读这一节**
- **第 1-9 章：技术选型调研** — 记录了切分算法、检索策略、表格处理、评测体系等各环节的技术调研和方案对比，是设计决策的依据
- **第 10 章：最终设计方案** — 基于前面的调研，给出 Graph RAG 的完整系统设计，包括双方案（LightRAG / GraphRAG）对比、数据处理流程、检索架构、**三路召回架构（ES + 向量RAG + GraphRAG）及分阶段演进建议**。**如果只想了解最终方案，直接看第 10 章**

### 术语表

| 术语 | 说明 |
|------|------|
| RAG | Retrieval-Augmented Generation，检索增强生成。先从知识库检索相关内容，再交给 LLM 生成回答 |
| Graph RAG | 在 RAG 基础上引入知识图谱，通过实体和关系的结构化检索增强召回能力 |
| LightRAG / GraphRAG | 两种 Graph RAG 的开源实现方案，详见第 1 章和第 10 章 |
| embedding | 将文本转化为向量表示，用于语义相似度计算 |
| BM25 | 基于关键词频率的经典文本检索算法，擅长精确匹配 |
| Reranker | 精排模型，对初步召回的结果做二次排序，提升相关性 |
| chunk | 文档切分后的文本片段，是检索的基本单元 |
| Text-to-SQL | 将自然语言问题转化为 SQL 查询，用于精确数值查询 |
| 极大团 | 图论概念，指图中所有节点两两相连的最大子图。本系统用于语义切分（详见第 3 章） |
| Leiden 算法 | 社区检测算法，用于将图谱中紧密关联的实体聚类成社区（仅 GraphRAG 方案使用） |

---

## 1. GraphRAG vs LightRAG

### 1.1 核心设计理念

**GraphRAG（微软）：预计算重于查询**

- 核心痛点：传统 RAG 擅长回答具体的"针尖"问题（如"A的生日是哪天？"），但无法回答全局性问题（如"这几份财报中主要隐含的风险主题是什么？"）
- 策略：通过构建图谱，利用 Leiden 算法将节点聚类成"社区（Community）"，并用 LLM 预先为每个社区生成摘要
- 比喻：就像写一本书的详细目录和每一章的梗概。查询时先看梗概，而不是从第一页翻到最后一页

**LightRAG（香港大学）：敏捷检索与双层关注**

- 核心痛点：GraphRAG 成本极高（Token 消耗大），且索引重建困难（新增数据需要重新聚类）
- 策略：同时关注"具体实体（Low-level）"和"抽象概念（High-level）"，不依赖繁重的社区预计算，而是依靠高效的向量检索与图结构的结合
- 比喻：像一个超级索引系统，既有按关键字查的词典，也有按主题查的分类表，且新书进来插进去就行，不用重印整本书

### 1.2 检索机制详解

#### GraphRAG 的查询机制（两种模式）

**模式 1：全局搜索（Global Search）— 针对"总结性/全集"问题**

```
用户提问："数据集中的主要冲突是什么？"
    │
    ▼
社区筛选（Community Filtering）
    │  系统设定一个社区层级（比如 Level 2）
    │  将查询与该层级的所有社区摘要进行匹配
    ▼
生成中间答案（Map Step）
    │  将筛选出的社区摘要作为 Context
    │  LLM 针对每个社区生成评分和中间答案
    ▼
聚合（Reduce Step）
    │  过滤掉评分低的社区答案
    │  将高分答案合并，生成最终的全局回答
    ▼
边搜索策略：无。全局搜索不走图的边，走的是预计算好的层级树
```

**模式 2：局部搜索（Local Search）— 针对"具体实体"问题**

```
用户提问："洋葱骑士是谁？"
    │
    ▼
实体识别：从问题中提取命名实体
    │
    ▼
子图提取（Subgraph Extraction）
    │  在图谱中找到这些实体节点
    │  沿边搜索：抓取 1-N 跳邻居和连接的原始文本块
    │  （实际实现中会根据 token budget 动态扩展，不仅限于 1 跳）
    ▼
上下文构建：将选中的实体描述、关系描述放入 Prompt
```

#### LightRAG 的查询机制（双层检索范式）

```
用户查询
    │
    ▼
Step 1: 查询分析与关键词生成（Query Profiling）
    │  LLM 分析用户 Query，生成两类检索键：
    │  ├── Local Keywords：具体实体名（如 "Elon Musk", "Tesla"）
    │  └── Global Keywords：抽象主题（如 "Electric Vehicle Market"）
    │
    ▼
Step 2: 双重检索（Dual-Level Retrieval）— 两条路径并行
    │
    ├── 路径 A: 低层级检索（Specific/Low-level）
    │   │  数据源：具体的实体节点
    │   │  搜索动作：将 Local Keywords 向量化，在实体 Vector Index 中做 ANN 搜索
    │   └── 沿边策略：找到实体后，通过 Entity -> Linked Chunks 找回相关原始文本块
    │
    └── 路径 B: 高层级检索（Abstract/High-level）
        │  数据源：关系节点（关系承载抽象语义，如"A 导致了 B 的破产"）
        │  搜索动作：将 Global Keywords 向量化，在关系 Vector Index 中搜索
        └── 沿边策略：Relation -> Linked Entities -> Linked Chunks
    │
    ▼
Step 3: 图结构融合与去重（Graph Pruning）
    │  从路径 A 和 B 中检索到大量实体、关系和文本块
    │  去除重复的文本块，保留最相关的图数据
    └── 经过筛选和去重后的数据进入 LLM 上下文窗口
```

#### 检索机制对比总结

| 特性 | GraphRAG | LightRAG |
|------|----------|----------|
| 核心数据单元 | 社区（Community） | 实体与关系（Entity & Relation） |
| 检索触发机制 | 遍历预生成的摘要（Global）或实体匹配（Local） | 向量相似度匹配直接定位图节点 |
| 沿边搜索策略 | 静态/有限：Local 模式扩展 1-N 跳；Global 模式不走边 | 动态/索引化：向量找到节点，再通过 Node -> Edge -> Chunk 映射链回溯 |
| 筛选/剪枝 | 依赖社区评分（LLM 打分，低分丢弃） | 依赖向量距离（距离远的不检索，合并重复 Chunk） |
| 增量更新 | 极难：新数据可能改变图拓扑，需全量重跑社区聚类和摘要 | 极易：新节点/新边插入向量库，不影响旧结构 |

### 1.3 核心对比

| 维度 | GraphRAG | LightRAG |
|------|----------|----------|
| 索引成本 | 高（社区检测 + 摘要生成，约 3-5 倍） | 低（简化流程） |
| 增量更新 | 不支持/困难 | 原生支持 |
| 全局问答 | 强（社区摘要天然支持跨文档全局概括） | 通过高层级检索近似实现，够用但不如社区摘要精准 |
| 查询延迟 | 较高（Global Search 的 Map-Reduce 消耗大量 token） | 较低 |
| 实现复杂度 | 高 | 中等 |

### 1.4 GraphRAG 的核心优势场景

LightRAG 在日常检索场景更实用，但 GraphRAG 在以下场景有不可替代的优势：

#### 场景 1：题材/板块自动聚类

**用户问："光伏产业链有哪些关键公司？上下游关系是什么？"**

- **LightRAG**：向量搜"光伏产业链"→ 命中若干实体和关系 → 返回零散结果。能找到"隆基绿能做硅片"、"通威做硅料"，但这些是独立返回的，没有全景图
- **GraphRAG**：Leiden 算法在建索引时就已经把"隆基、通威、阳光电源、中环股份、硅料、硅片、电池片、组件"聚成了一个社区，社区摘要直接写着：
  > "该社区围绕光伏产业链，上游硅料（通威）→ 中游硅片/电池（隆基、中环）→ 下游组件/电站（阳光电源），核心驱动因素是硅料价格和装机量..."

**本质差异**：社区检测做的事情就是"自动发现哪些股票应该被串在一起"，这不是检索能替代的。

#### 场景 2：历史信号回溯（跨文档模式发现）

**用户问："历史上美联储加息周期中，A股银行板块通常怎么表现？"**

- **GraphRAG**：如果把多年的研报都入库了，社区检测会自然地把"美联储加息"、"中美利差"、"银行净息差"、"银行板块表现"聚到相关社区。社区摘要会沉淀出跨文档的规律：
  > "在 2015、2017、2022 年的加息周期中，银行板块初期承压（净息差预期收窄），但中后期受益于存贷利差扩大..."
- **LightRAG**：能找到 2022 年某篇研报里提到"加息影响银行"，也能找到 2017 年的另一篇，但它不会主动把跨年份的信息归纳成模式。需要 Agent 做多轮检索 + 总结，且 Agent 不一定知道该去查 2015 年

**本质差异**：社区摘要在索引阶段就把散落在几十份研报里的信息聚合了。

#### 场景 3：多跳因果链的全景展示

**用户问："猪周期拐点会影响哪些板块？"**

GraphRAG 的社区结构天然适合这个场景：

```
社区 A（养殖产业链）：
  猪肉价格 → 养殖利润 → 牧原/温氏扩产 → 饲料需求（海大集团）

社区 B（CPI 传导链）：
  猪肉价格 → CPI 上行 → 货币政策收紧预期 → 利率敏感板块承压

社区 C（消费替代链）：
  猪肉价格上涨 → 消费者转向禽肉/水产 → 圣农发展/国联水产受益
```

用户问一个问题，GraphRAG 的全局搜索能同时命中三个社区摘要，给出完整的影响图谱。

**LightRAG 的局限**：能找到"猪肉价格→养殖利润"这种直接关系，但"猪肉价格→CPI→货币政策→利率敏感板块"这条间接链，向量检索很难一次性串起来——"猪周期"和"利率敏感板块"的 embedding 距离太远了。

### 1.5 金融场景特殊考量

#### 实体消歧 — Graph RAG 的核心难点

金融场景的消歧复杂度远超一般领域：

**同一实体的多种指代**：
- "腾讯" / "腾讯控股" / "0700.HK" / "Tencent" / "鹅厂"
- "宁德时代" / "CATL" / "300750.SZ" / "宁王"

**母子公司 vs 独立实体**：
- "蚂蚁集团"和"阿里巴巴"是两个实体，但关系极其紧密
- 研报里"公司"可能指母公司也可能指合并报表口径

| 场景 | LightRAG | GraphRAG |
|------|----------|----------|
| 实体未合并（"腾讯"和"腾讯控股"各自独立） | 向量检索能部分容错——两个名字的 embedding 距离近，查一个大概率也能命中另一个 | 社区检测会把它们分到不同社区，摘要各说各的，全局概括直接出错 |
| 实体错误合并（把"中国平安"和"平安银行"合成一个） | 影响局部——该实体的关系描述混乱，但不影响其他实体 | 影响全局——错误实体拉入错误社区，社区摘要被污染，且修复需重建社区 |

**实际建议**：金融场景必须在抽取阶段加一层 entity resolution，用证券代码/统一社会信用代码做硬锚点。LightRAG 对消歧错误的容错性明显更好。

#### 时间维度 — 金融图谱的特殊挑战

一般知识图谱的关系是相对稳定的（"北京是中国首都"），但金融图谱的关系高度时变：

- Q3 营收增长 15%，Q4 可能变成 -5%
- "A 是 B 的第一大客户"今年成立，明年可能不是
- 同一个实体"贵州茅台"，2023 年报和 2024 年报的描述完全不同

**GraphRAG 的问题**：社区摘要是静态快照。2023 年报入库后生成的社区摘要写着"营收高速增长"，2024 年报进来说"增速放缓"，旧摘要不会自动更新。要么全量重建，要么容忍过时信息——金融场景下过时信息比没有信息更危险。

**LightRAG 的优势**：没有摘要层，每次检索都是从实体/关系的向量匹配开始，回溯到原始 chunk。只要 chunk 带了时间标签，LLM 在生成阶段可以自行判断时效性。

**实际建议**：图谱的边应该带时间戳属性：

```json
{
  "source": "贵州茅台",
  "target": "营收增长",
  "relation": "财务表现",
  "description": "2024年Q3营收同比增长15.5%",
  "time_range": "2024-Q3",
  "source_chunks": ["c_0042"],
  "weight": 3
}
```

检索时可以按时间窗口过滤。这在 LightRAG 上加很简单（向量检索后做 post-filter），在 GraphRAG 上加很痛苦（社区摘要没法按时间过滤）。

#### 多跳推理链 — Agent 规划驱动，非图谱遍历

金融分析师的典型推理链：

> "台积电产能紧张 → 影响苹果 iPhone 出货 → 影响苹果营收预期 → 影响苹果股价 → 影响纳斯达克指数"

这是一个 4 跳的因果链。**现实情况：两种方案都不能很好地处理长链多跳**。这不是 Graph RAG 的问题，而是当前所有 RAG 方案的共同短板。

**金融 Agent 的实际解法**：

```
用户问题："台积电产能紧张对A股消费电子板块有什么影响？"
    │
    ▼
Agent 拆解为多步检索（ReAct / Plan-and-Execute）：
    Step 1: Graph RAG → "台积电产能紧张影响了哪些下游客户？"
    Step 2: Graph RAG → "苹果/高通供应链受限对哪些A股公司有影响？"
    Step 3: Graph RAG → "这些公司属于什么板块？近期表现如何？"
    Step 4: LLM 综合三步结果生成最终回答
```

**关键点**：多跳推理不应该依赖图谱的遍历深度，而应该由 Agent 的规划能力来驱动。Graph RAG 负责每一步的精准召回，Agent 负责串联。

### 1.6 方案选择矩阵

| 能力 | LightRAG 更强 | GraphRAG 更强 |
|------|:-------------:|:-------------:|
| 精确实体查询（"腾讯Q3营收分析"） | ✓ | |
| 增量更新（每天新研报入库） | ✓ | |
| 查询延迟和成本 | ✓ | |
| 实体消歧容错性 | ✓ | |
| 时间维度处理 | ✓ | |
| 题材/板块自动聚类 | | ✓ |
| 跨文档模式发现（历史信号回溯） | | ✓ |
| 多跳因果链的全景展示 | | ✓ |
| 全局概括（"行业整体风险"） | | ✓ |

**金融 Agent 的实际选择不是二选一，而是分层**：

```
金融 Agent
    │
    ├── 日常问答/检索 → LightRAG 或 ES+向量RAG（高频、低延迟、增量更新）
    │     "腾讯Q3游戏业务怎么样？"
    │     "宁德时代的主要客户有哪些？"
    │
    ├── 产业链分析/题材挖掘 → GraphRAG（低频、高价值、预计算）
    │     "光伏产业链全景图"
    │     "猪周期影响哪些板块"
    │     "历史上降息周期的受益行业"
    │
    ├── 精确数值 → Text-to-SQL
    └── 实时行情 → API
```

GraphRAG 的社区摘要可以不用实时更新——产业链结构、历史规律这些东西变化慢，一周甚至一个月重建一次就够了。日常的增量研报走 LightRAG 或 ES+向量RAG，定期做一次全量 GraphRAG 重建来更新产业图谱和历史模式。

### 1.7 开源方案

-   GraphRAG（微软官方）：`github.com/microsoft/graphrag`
-   LightRAG：`github.com/HKUDS/LightRAG`
-   nano-graphrag：`github.com/gusye1234/nano-graphrag`（轻量复现）
-   fast-graphrag：GraphRAG 性能优化版本

### 1.8 结论

~~除非有非常明确的全局摘要需求，LightRAG 是更务实的选择。~~

**修正后的结论**：

- **日常检索场景**：LightRAG 或 ES+向量RAG 是更务实的选择——增量更新、低延迟、成本可控
- **产业链/全局分析场景**：GraphRAG 有不可替代的价值——社区聚类和预计算摘要能发现向量检索发现不了的模式
- **生产推荐**：双层架构，日常走轻量路径，全局分析走 GraphRAG（可离线预计算）

> 详细的双方案对比、索引成本估算见第 10 章。三路召回架构（ES + 向量RAG + GraphRAG）见第 10.4 节。

---

## 2. 文章切分方案

### 主流切分算法

1.  **固定窗口 + 重叠**：chunk_size=512, overlap=128，简单但粗暴，金融场景效果差
2.  **递归字符切分**（LangChain RecursiveCharacterTextSplitter）：按段落 > 句子 > 字符逐级切
3.  **语义切分**（Semantic Chunking）：用 embedding 相似度检测语义断点，相邻句子相似度骤降时切分
4.  **文档结构感知切分**：按 Markdown 标题、PDF 的 section/subsection 切分
5.  **Agentic Chunking**：用 LLM 判断每个段落是否应该归入当前 chunk，成本高但效果好

### 金融场景推荐

-   年报/研报：结构感知切分，按章节切分，表格单独处理
-   公告/新闻：语义切分，篇幅短，语义切分够用
-   财务报表：不要切分，整表作为一个 chunk，或转成结构化数据直接查询

---

## 3. 保序极大团切分算法（当前方案）

> 本章介绍切分算法原理。该算法在系统中的实际应用见第 8.1 节（正文处理流程）和第 10.1 节（切分层在 Graph RAG 中的角色）。

### 算法流程

1.  将文章拆分成句子 list
2.  在局部窗口（N=20~80）内计算所有句子对的 embedding 余弦相似度
3.  相似度超过阈值 θ 的句子之间连边，构建相似度图
4.  在图上求极大团（Bron-Kerbosch 算法）
5.  保持原始文档顺序不变，极大团决定哪些连续句子应合并为一个 chunk
6.  chunk 长度到达上限时，在当前句子结束处切断

### 重叠句子归属策略

-   当某个句子同时属于多个极大团时，根据 chunk 长度决定归属
-   如果前一个 chunk 长度不够，将重叠句子向前合并

### 与主流算法对比

| 维度 | 固定窗口+重叠 | 语义切分（相邻突变检测） | 保序极大团 | Agentic Chunking |
|------|---------------|------------------------|-----------|-----------------|
| 切分依据 | 字符/token 数 | 相邻句子相似度骤降 | 局部窗口内两两相似度 | LLM 判断 |
| 语义完整性 | 差，硬切 | 中等，只看相邻关系 | 较好，团内两两内聚 | 最好 |
| 计算成本 | 几乎为零 | 低（N次相似度计算） | 中等（窗口内两两计算+求团） | 高（大量LLM调用） |
| 可读性 | 好（保序） | 好（保序） | 好（保序） | 好 |
| 实现复杂度 | 极低 | 低 | 中等 | 低但贵 |

### 优势

1.  比语义切分更严格：要求团内所有句子两两相似，不只是相邻相似
2.  比纯极大团聚合务实：保留原始语序，避免乱序拼接
3.  性价比好：比固定窗口智能，比 Agentic Chunking 便宜

### 劣势与注意事项

1.  对 embedding 模型依赖重：金融专业术语如果模型没见过，相似度计算不准
2.  阈值 θ 和窗口 N 需要调参：不同类型文档最优参数可能不同
3.  无法感知文档结构：纯语义驱动，忽略标题、章节、表格等显式结构信号
4.  对短句不友好："单位：万元"等短句 embedding 信息量少，归属可能不稳定

### 建议优化

-   **结构信号融合**：如果两个句子跨了章节标题，直接不连边，用文档结构做硬约束
-   **切断点优化**：到达长度上限时，往回看几句，找团内相似度最低的边切分，而非硬切

---

## 4. 更前沿的切分/检索方案

### Late Chunking（Jina AI）

-   先不切分，整篇文档过长上下文 embedding 模型，每个 token 拿到全文上下文表征，然后再切分做 pooling
-   每个 chunk 的 embedding 天然包含全文上下文，不存在指代丢失问题
-   依赖长上下文 embedding 模型（jina-embeddings-v3 支持 8K）

### Contextual Retrieval（Anthropic）

-   给每个 chunk 用 LLM 生成一段上下文描述，拼在 chunk 前面再做 embedding
-   信息只增不减，不存在压缩丢失
-   实验显示检索失败率降低 49%（结合 BM25 和 Reranker 可达 67%）

### ColBERT / ColPali（多表征索引）

-   保留 token 级别的多向量表征，检索时做 late interaction
-   细粒度匹配，对"一段话包含多个指标"的场景特别有效

### Proposition-based Chunking（Dense X Retrieval，清华）

-   用 LLM 把文档拆成独立命题，每个命题是自包含的事实陈述
-   不存在指代问题，金融场景天然适合
-   缺点：LLM 调用成本高

### RAPTOR（斯坦福）

-   递归聚类生成多层摘要树，检索时可命中摘要层或原文层
-   在 QuALITY 长文档问答上比传统 RAG 提升 20% 准确率

---

## 5. 实体指代与关联关系破碎问题

### 实体指代问题

切分后"该公司"、"该指标"等代词丢失指代对象。

解决方案：

1.  **上下文注入**：切分后给每个 chunk 加元数据前缀（文档名、章节、主题）
2.  **指代消解预处理**：切分前用 LLM 将代词替换为具体实体名
3.  **Parent-Child 索引**：小 chunk 用于检索，命中后返回父级大 chunk
4.  **知识图谱辅助**：用 LightRAG/GraphRAG 抽取实体关系，查询时同时检索相关实体上下文

### 关联关系破碎问题

"A公司收购B公司"被切到两个 chunk 里。

解决方案：

1.  **增大 overlap**：简单有效，但增加存储和噪声
2.  **关系感知切分**：切分前先做关系抽取，确保关联实体在同一 chunk
3.  **多粒度索引**：同时维护段落级和文档级索引，查询时融合
4.  **Graph RAG**：把关系显式存储在图谱中，不依赖 chunk 完整性

---

## 6. RAG 内容选择策略

> 本章的混合路由架构是基础版本。引入 Graph RAG 后，路由扩展为文本→LightRAG / 表格→BM25+向量 / 数值→SQL，详见第 10.3.3 节。

### 适合 RAG 的内容

-   管理层讨论与分析（MD&A）
-   研报核心观点、逻辑推导
-   风险因素描述、行业分析
-   公告中的事件描述
-   会议纪要、调研记录
-   监管政策、法规条文

### 不适合 RAG 的内容

| 内容 | 更好的方案 |
|------|----------|
| 结构化财务数据（营收、利润、PE等） | Text-to-SQL |
| 实时行情、K线数据 | API 直接查询 |
| 需要精确计算的（同比增长率、估值） | Code Interpreter |
| 大量时间序列对比 | 专门的分析引擎 |
| 目录、页眉页脚、免责声明 | 直接过滤掉 |

### 按信息价值分

**高价值（必须入库）**

-   包含因果关系："因为…所以…"、"受…影响"
-   包含判断/预测："预计"、"展望"、"我们认为"
-   关键数据+解释：数字背后的原因
-   差异化信息：分析师独到见解

**低价值（可不入库或降权）**

-   纯模板化内容：每份年报都有的固定表述
-   重复信息：同一事件在摘要和正文中重复出现，只保留详细版本
-   纯数字罗列：没有解释的数据表

### 推荐架构：混合路由

```
查询进来
  ↓
路由判断（Agent/分类器）
  ↓
├── 定性问题 → RAG 检索文本
├── 定量问题 → SQL 查结构化数据
├── 计算问题 → SQL + Code Interpreter
└── 混合问题 → SQL 取数据 + RAG 取解释，合并给 LLM
```

---

## 7. Chunk 入库内容结构

> 本章讨论的是传统 RAG 的 chunk 入库策略。引入 Graph RAG 后，文本检索路径被 LightRAG 替代，chunk 的主要角色变为实体抽取输入和溯源单元（详见第 10.1 节"切分层在 Graph RAG 中的角色"）。表格检索仍使用本章描述的方案。

### 方案对比

| 方案 | embedding 基于 | 送给 LLM | 优点 | 缺点 |
|------|---------------|---------|------|------|
| 基础方案 | meta + chunk 原文 | meta + chunk 原文 | 无信息损失 | 概括性查询召回一般 |
| 摘要检索 | meta + 摘要 | meta + chunk 原文 | 概括性查询召回好 | 细节查询召回下降 |
| 上下文增强 | meta + context + chunk 原文 | meta + chunk 原文 | 信息只增不减 | 需要 LLM 生成 context |
| 多路召回 | 同时索引摘要和原文 | meta + chunk 原文 | 两者互补，效果最好 | 工程复杂度翻倍 |

### 摘要做检索的实际验证

| 查询类型 | 摘要做检索 | 原文做检索 |
|---------|----------|----------|
| 概括性查询（"核心竞争力是什么"） | 更好 | 一般 |
| 细节查询（"2024年Q3营收多少"） | 更差 | 更好 |
| 趋势分析（"行业发展趋势"） | 更好 | 一般 |
| 精确条款（"违约金比例"） | 更差 | 更好 |

中文社区实践反馈：摘要检索在 top-K recall 上约提升 5-15%，但主要来自概括性查询，细节查询是下降的。

### 推荐方案：多路召回

```
查询进来
  ↓
同时检索两个索引
├── 索引1：meta + 摘要 embedding → 召回概括性相关的 chunk
├── 索引2：meta + 原文 embedding → 召回细节匹配的 chunk
  ↓
合并去重 + Reranker 精排
  ↓
top-K 原文送给 LLM
```

如果只能选一个，**保留原文做检索更安全**，金融场景细节查询占比高。

### 推荐存储结构

```json
{
  "meta": "腾讯2024年报 | 管理层讨论与分析",
  "context": "本段来自腾讯2024年报第三章，讨论游戏业务海外营收情况",
  "content": "原始chunk内容...",
  "embedding": "基于 meta + context + content 生成"
}
```

---

## 8. 数据分类处理方案

不同类型的数据采用不同的处理和检索策略，不能一刀切。

### 8.1 正文文本处理

#### 处理流程

```
PDF 原文
  │
  ▼
┌─────────────────────────────────────────────────────┐
│  PDF 清洗层  (pdf_parsing_optimized.py)              │
│                                                      │
│  PDFParser / _OptimizedPDFSegmentsMixin              │
│  ├── 跳过目录页        is_directory_page()           │
│  ├── 首页特殊处理      _process_first_page()         │
│  ├── 去重复行          remove_duplicate_text()       │
│  ├── 去免责声明        remove_disclaimer()           │
│  ├── 去页脚            remove_page_footer()          │
│  ├── 去联系方式        remove_contact_info()         │
│  ├── 去表格            _remove_tables()              │
│  ├── 去纯符号行        _remove_symbol_lines()        │
│  └── 去图表标注        graph_check()                 │
└──────────────────────┬──────────────────────────────┘
                       │
                       ▼
┌─────────────────────────────────────────────────────┐
│  句子切分  (topic_segmentation.py)                    │
│                                                      │
│  cut_sentences() — spaCy 优先，正则兜底               │
│  ├── 标题预切  detect_heading_line() — 遇标题先切一刀 │
│  └── QA 模式预切  pattern_segment_array()            │
└──────────────────────┬──────────────────────────────┘
                       │
                       ▼
┌─────────────────────────────────────────────────────┐
│  语义切分层  (topic_segmentation.py)                  │
│                                                      │
│  calculate_similarity_matrix()                       │
│  ├── 局部窗口内计算 embedding 余弦相似度              │
│  ├── 阈值过滤，构建相似度图 (NetworkX)                │
│  ├── Bron-Kerbosch 求极大团  find_cliques_recursive()│
│  ├── 重叠处理  handle_overlap()                      │
│  ├── 间隙填充 + 连续序列检测  post_process           │
│  └── 长度归一化  [min_length, max_length]            │
└──────────────────────┬──────────────────────────────┘
                       │
                       ▼
┌─────────────────────────────────────────────────────┐
│  入库结构                                            │
│                                                      │
│  {                                                   │
│    "meta": "公司名+时间+章节" (20-40字),              │
│    "content": "chunk原文" (~500字),                   │
│    "embedding": 基于 meta+content 生成                │
│  }                                                   │
│                                                      │
│  检索方式：embedding 语义匹配                         │
└─────────────────────────────────────────────────────┘
```

#### 核心代码位置

| 功能 | 文件 | 核心方法 |
| --- | --- | --- |
| PDF 清洗 | `pdf_parser/pdf_parsing_optimized.py` | `PDFParser.process_text()` |
| 标题检测 | `pdf_parser/pdf_parsing_optimized.py:189` | `detect_heading_line()` |
| 表格剔除 | `pdf_parser/pdf_parsing_optimized.py:831` | `_remove_tables()` |
| 句子切分 | `topic_method/topic_segmentation.py` | `cut_sentences()` |
| 标题预切 | `topic_method/topic_segmentation.py:242` | `pattern_segment_array()` |
| 极大团切分 | `topic_method/topic_segmentation.py:77` | `find_cliques_recursive()` |
| 重叠处理 | `topic_method/helpers/handle_conflict.py:38` | `handle_overlap()` |
| 相似度计算 | `topic_method/helpers/calculate_similarity.py` | `calculate_similarity_matrix()` |

#### 关键设计决策

-   使用原始版 `topic_segmentation.py`（极大团），不用优化版（连通分量），保证内聚性
-   标题预切在极大团之前执行，天然实现了 section 约束，不会跨章节聚合
-   meta 占比 4-8%（20-40字 / 500字），对 embedding 质量影响可忽略
-   meta 拼接是必要的：金融文档大量使用"本公司""该指标"等代词，不拼 meta 会丢失实体信息

### 8.2 表格处理

#### 处理流程

```
PDF 页面
  │
  ▼
┌─────────────────────────────────────────────────────┐
│  表格检测与提取  (pdf_parsing_optimized.py)           │
│                                                      │
│  _extract_tables_as_segments()                       │
│  ├── page.find_tables()  — PyMuPDF 边框检测          │
│  ├── tab.extract()       — 提取全部 cell 数据        │
│  ├── tab.to_pandas()     — 兜底提取                  │
│  └── _rows_to_markdown() — 转完整 markdown           │
└──────────────────────┬──────────────────────────────┘
                       │
                       ▼
┌─────────────────────────────────────────────────────┐
│  文本/表格混排  (pdf_parsing_optimized.py)            │
│                                                      │
│  parse_segments_from_url()                           │
│  ├── 文本块 bbox 与表格 bbox 重叠检测                 │
│  │   _rect_overlap() — 排除表格区域内的文本           │
│  ├── 按 y 坐标排序（阅读顺序）                        │
│  └── 线性扫描：连续文本合并，遇表格切断               │
│                                                      │
│  输出：                                               │
│  ┌─────────────────────────────────────┐             │
│  │ {"type":"text",  "content":"表格前正文(含标题)"}   │
│  │ {"type":"table", "content":"完整markdown表格"}     │
│  │ {"type":"text",  "content":"表格后正文(含尾注)"}   │
│  └─────────────────────────────────────┘             │
└──────────────────────┬──────────────────────────────┘
                       │
                       ▼
┌─────────────────────────────────────────────────────┐
│  RAG 骨架提取（入库阶段）                             │
│                                                      │
│  从已有数据中组装：                                    │
│  ├── meta        — 上层拼接（公司名+时间）            │
│  ├── 表格标题    — 前一个 text segment 末尾            │
│  ├── cell 标题   — rows[0] 单独提取（需新增）         │
│  └── 表格尾注    — 后一个 text segment 开头            │
│                                                      │
│  入库结构：                                           │
│  {                                                   │
│    "meta": "公司名+时间",                             │
│    "skeleton": "meta+标题+cell标题+尾注",             │
│    "full_table": "完整markdown表格",                  │
│    "bm25_index": skeleton,                           │
│    "embedding": 基于 skeleton 生成                    │
│  }                                                   │
│                                                      │
│  检索方式：BM25 + embedding 双路召回                  │
│  ├── BM25  → 精确匹配（数值、列名、实体名）          │
│  └── 向量  → 语义匹配（发现性查询）                  │
│  生成时：命中后取 full_table + meta 送给 LLM          │
└─────────────────────────────────────────────────────┘
```

#### 核心代码位置

| 功能 | 文件 | 核心方法 |
| --- | --- | --- |
| 表格检测 | `pdf_parsing_optimized.py:368` | `_extract_tables_as_segments()` |
| markdown 转换 | `pdf_parsing_optimized.py:316` | `_rows_to_markdown()` |
| 重叠检测 | `pdf_parsing_optimized.py:330` | `_rect_overlap()` |
| 混排输出 | `pdf_parsing_optimized.py:434` | `parse_segments_from_url()` |
| 页码过滤 | `pdf_parsing_optimized.py:359` | `_should_filter_text()` |

#### 关键设计决策

-   表格骨架（标题+列头+尾注）做 RAG 索引，不含具体数值——数值对 embedding 无语义贡献
-   表格用 BM25 + embedding 双路召回——BM25 擅长精确匹配（数值、列名），embedding 擅长语义发现（用户措辞与表格内容不一致时）
-   TARGET 基准测试显示：dense embedding 在表格级发现任务上显著优于 BM25，但 BM25 在精确数值匹配上更强，双路互补
-   命中后返回完整原始表格（HTML 格式）给 LLM——骨架只负责召回，生成靠完整数据
-   cell 标题从 `rows[0]` 提取，是当前唯一需要新增的逻辑
-   券商研报表格 80-90% 能被 PyMuPDF 正确提取，无边框/跨页/合并单元格的边界 case 比例低

#### 表格序列化格式：Markdown vs HTML

检索和生成使用不同格式，各取所长：

-   **检索阶段（embedding/BM25 索引）**：使用 Markdown 骨架——更干净，token 省 ~43%，embedding 质量更高
-   **生成阶段（送给 LLM）**：使用 HTML 原始表格——LLM 对表格结构理解更准确，内容提取准确率显著更高

LLM 表格结构理解对比（SUC 基准测试，WSDM 2024，GPT-3.5）：

| 任务 | Markdown | HTML | 差距 |
| --- | --- | --- | --- |
| 列检索 | 35.33% | 63.33% | HTML 赢 28pp |
| 表格大小检测 | 40.67% | 67.00% | HTML 赢 26pp |
| 表格分区 | 92.33% | 96.67% | HTML 赢 4pp |
| 单元格查找 | 43.33% | 44.00% | 基本持平 |
| 行检索 | 42.33% | 42.00% | 基本持平 |
| 合并单元格 | 78.00% | 76.67% | Markdown 赢 1pp |
| 综合准确率 | ~54.57% | 65.43% | HTML 赢 ~11pp |

HTML 优势不只是布局识别——列检索（+28pp）直接影响 LLM 从表格中提取正确 cell 值的能力。用户问"游戏业务营收多少"，LLM 需要定位"营收"列 + "游戏业务"行的交叉值，HTML 在这个任务上准确率近乎翻倍。

RAG 检索准确率对比：

| 格式 | 检索准确率 |
| --- | --- |
| Semantic Markdown | ~89% |
| Plain text | ~71% |
| Raw HTML | ~62% |
| Cleaned HTML（HtmlRAG） | 优于 Markdown（6 个 QA 基准） |

Raw HTML 标签对 embedding 是噪声，但清洗后的 HTML 反而更好。骨架本身是自然语言（标题+列头），Markdown 格式足够。

Token 消耗：Markdown 比 HTML 省 ~43%，检索阶段用 Markdown 可显著降低索引成本。

合并单元格处理：

-   HTML 原生支持 `colspan`/`rowspan`，多层表头直接表达
-   Markdown 完全不支持合并单元格
-   券商研报大部分是简单平表，少量复杂表用 HTML 存储可完整保留结构

最终方案：

```
embedding 索引：Markdown 骨架（标题+列头+尾注）→ 干净、省 token
BM25 索引：Markdown 骨架 → 关键词匹配
存储原始表格：HTML 格式 → 结构完整
送给 LLM：HTML 原始表格 + meta → 内容提取准确率最高
```

#### 表格检索效果数据（来自公开评测）

| 方案 | Recall@5 / 准确率 | 来源 |
| --- | --- | --- |
| 朴素 RAG（单路向量） | 74% Recall@5 | 生产系统报告 |
| 摘要检索 + 结构化存储（双层） | 87% Recall@5（+13pp） | 生产系统报告 |
| 加 Reranker | 再提升 15-30% | 跨多个评测 |
| TableRAG on WTQ | 57.03% 准确率 | NeurIPS 2024 |
| TableRAG on 1000x1000 大表 | 68.4% 准确率 | 其他方法超出上下文限制 |

#### 值得关注的前沿方案

-   **TableRAG（NeurIPS 2024）**：将表格检索拆为 Schema 检索（找相关列）+ Cell 检索（定位具体值），在大表场景优势明显
-   **T2-RAGBench**：32,908 条金融文本+表格混合问答，验证了 hybrid BM25（dense + sparse）对混合数据的有效性
-   **多向量检索（ColBERT 风格）**：不把整表压缩成单向量，而是保留 token 级表征，避免"向量稀释"问题

### 8.3 系统级检索架构

#### 当前架构（引入 Graph RAG 后）

```
用户查询
  │
  ▼
┌─────────────────────────────────────────────────────┐
│  查询路由（Agent / 分类器）                           │
│  ├── 文本类问题 → LightRAG                           │
│  ├── 表格类问题 → BM25 + 向量双路召回                │
│  ├── 精确数值   → Text-to-SQL                        │
│  └── 混合问题   → 多路                               │
└──────────────────────┬──────────────────────────────┘
                       │
          ┌────────────┼────────────┐
          ▼            ▼            ▼
┌──────────────┐ ┌──────────────┐ ┌──────────────┐
│ 正文文本     │ │ 表格骨架     │ │ 结构化数据   │
│              │ │              │ │              │
│ LightRAG    │ │ BM25 + 向量  │ │ Text-to-SQL  │
│ (图谱检索)  │ │ 双路召回     │ │ 精确查询     │
└──────┬───────┘ └──────┬───────┘ └──────┬───────┘
       │                │                │
       ▼                ▼                ▼
┌─────────────────────────────────────────────────────┐
│  合并去重 + Reranker 精排                             │
└──────────────────────┬──────────────────────────────┘
                       │
                       ▼
┌─────────────────────────────────────────────────────┐
│  送给 LLM 生成回答                                    │
│  ├── 正文 → 溯源 chunk（meta + content）+ 图谱三元组 │
│  ├── 表格 → 取完整原始表格 + meta                     │
│  └── SQL 结果 → 结构化数据                            │
└─────────────────────────────────────────────────────┘
```

> 完整的双方案（LightRAG / GraphRAG）检索流程对比见第 10.3 节。

### 8.4 不同数据类型处理对比

| 维度 | 正文文本 | 表格 | 结构化数据 |
| --- | --- | --- | --- |
| 清洗方式 | PDF 清洗流水线 | PyMuPDF find_tables | ETL 入库 |
| 切分方式 | 保序极大团 | 整表不切分 | 不切分 |
| 索引内容 | meta + chunk 原文 | meta + 骨架（标题+列头+尾注） | 表结构 + 字段 |
| 检索方式 | LightRAG（图谱检索） | BM25 + 向量双路召回 | Text-to-SQL |
| 送给 LLM | 溯源 chunk（meta + content）+ 图谱三元组 | meta + 完整原始表格 | SQL 查询结果 |
| 适合的查询 | 定性分析、观点、趋势、关系推理 | "XX公司营收表""分业务数据" | 精确数值、计算 |

---

## 9. 评测体系

### 检索质量评测

-   Recall@K：top-K 结果中包含正确答案的比例
-   MRR（Mean Reciprocal Rank）：正确答案的排名
-   用人工标注的 query-document 对做 ground truth

### 生成质量评测

-   **RAGAS**（`github.com/explodinggradients/ragas`）：Faithfulness、Answer Relevancy、Context Precision/Recall
-   **DeepEval**：支持幻觉检测
-   **LLM-as-Judge**：用 GPT-4/Claude 打分

### 金融专项指标

-   数字准确率（财务数据是否正确）
-   时间一致性（是否混淆了不同时期的数据）
-   实体归属准确率（指标是否对应到正确的公司）

### 在线评测

-   用户满意度、点击率、采纳率
-   Bad case 分析，持续迭代

---

## 10. Graph RAG 方案（LightRAG）

### 10.1 方案设计

#### 核心思路

-   Graph RAG 不替代普通 RAG，而是**替代普通 RAG 的文本检索路径**——通过实体/关系的向量匹配 + 图谱结构检索，一套系统覆盖文本类查询
-   表格 BM25 检索和 Text-to-SQL 保持独立，Graph RAG 替代不了精确数值匹配和结构化查询
-   两种方案（LightRAG / GraphRAG）共享 PDF 清洗和切分层，差异从实体抽取之后开始

#### 方案 A：LightRAG（推荐）

```
查询 → 路由（Agent / 分类器）
  ├── 文本类问题 → LightRAG.query()（一条路搞定）
  │     ├── 低层级检索（实体/关系描述的向量匹配）≈ 普通 RAG 语义检索
  │     ├── 高层级检索（主题/概念的向量匹配）≈ 概括性查询
  │     └── source_chunk_id 溯源 → 拿到原文
  ├── 表格类问题 → BM25 + 向量双路召回（已有）
  └── 精确数值   → Text-to-SQL（已有）
```

核心特点：

-   实体抽取后直接建图 + embedding，无社区检测步骤
-   双层检索（低层级精确实体 + 高层级主题概念）内置于 `LightRAG.query()`
-   原生支持增量更新，新文档直接融入已有图谱
-   查询路由简单：文本类统一走 LightRAG

#### 方案 B：GraphRAG（微软）

```
查询 → 路由（Agent / 分类器）
  ├── 文本类问题（全局概括）→ 社区摘要匹配
  │     ├── 命中社区摘要 → 直接作为上下文送 LLM
  │     └── 适合"行业整体趋势""所有公司共同风险"类查询
  ├── 文本类问题（局部精确）→ 实体/关系匹配
  │     ├── 实体向量匹配 → 子图提取 → source_chunk_id 溯源
  │     └── 适合"A的供应商""A和B的关系"类查询
  ├── 表格类问题 → BM25 + 向量双路召回（已有）
  └── 精确数值   → Text-to-SQL（已有）
```

核心特点：

-   实体抽取后额外做 Leiden 社区检测 + 多层社区摘要生成
-   全局查询走社区摘要，局部查询走实体匹配，路由粒度更细
-   不支持增量更新（新文档需重跑社区检测+摘要），或需自行实现增量社区合并
-   全局概括能力强，但索引成本高 3-5 倍

#### 双方案全量对比

| 维度 | 方案 A：LightRAG | 方案 B：GraphRAG |
| --- | --- | --- |
| 索引流程 | 实体抽取 → 直接建图 + embedding | 实体抽取 → Leiden 社区检测 → 多层社区摘要生成（额外 LLM 调用） |
| 检索机制 | 低层级/高层级双层向量匹配，统一接口 | 全局查询→社区摘要匹配，局部查询→实体匹配，两条路径 |
| 全局问答能力 | 通过高层级检索近似实现，够用但不如社区摘要精准 | 强，社区摘要天然支持跨文档全局概括 |
| 增量更新 | 原生支持，新文档直接融入已有图谱 | 需重跑社区检测+摘要，官方增量支持不完善 |
| 图存储 | 实体节点 + 关系边 + 描述 embedding | 实体节点 + 关系边 + 社区节点 + 社区摘要 + 多层 embedding |
| 查询路由复杂度 | 简单：文本类统一走 LightRAG.query() | 复杂：需区分全局查询（→社区摘要）和局部查询（→实体匹配） |
| 实现复杂度 | 中等，开箱即用 | 高，社区检测+摘要生成+增量更新均需额外开发 |
| 适合场景 | 实体级查询为主，文档更新频繁 | 全局概括查询为高频场景，文档相对稳定 |

#### 与现有方案的关系

| 模块 | 现有方案 | + LightRAG（方案 A） | + GraphRAG（方案 B） |
| --- | --- | --- | --- |
| PDF 清洗 | 不变 | 不变 | 不变 |
| 切分（保序极大团） | 不变 | 不变，chunk 作为实体抽取的输入单元 | 不变，chunk 作为实体抽取的输入单元 |
| 文本检索 | ES + 向量双路召回 | 替换为 LightRAG 单路 | 替换为 GraphRAG 双路（社区摘要 + 实体匹配） |
| 表格检索 | BM25 + 向量双路召回 | 不变 | 不变 |
| 结构化查询 | Text-to-SQL | 不变 | 不变 |
| 查询路由 | 定性→RAG / 定量→SQL | 文本→LightRAG / 表格→BM25+向量 / 数值→SQL | 全局文本→社区摘要 / 局部文本→实体匹配 / 表格→BM25+向量 / 数值→SQL |

#### 索引成本估算

| 阶段 | 当前方案 | + LightRAG（方案 A） | + GraphRAG（方案 B） |
| --- | --- | --- | --- |
| PDF 清洗 | CPU，忽略不计 | 不变 | 不变 |
| 切分（极大团） | embedding ~$0.01/篇 | 不变 | 不变 |
| 实体/关系抽取 | 无 | LLM 调用 ~$0.05-0.15/篇 | LLM 调用 ~$0.10-0.30/篇（额外要求识别实体类型+去重合并） |
| 社区检测+摘要 | 无 | 无 | Leiden 算法 + LLM 摘要生成 ~$0.20-0.50/篇 |
| 图谱构建 | 无 | NetworkX 内存操作，忽略 | NetworkX/Neo4j + 社区层级结构存储 |
| 向量索引 | embedding ~$0.01/篇 | 额外索引实体描述 ~$0.005/篇 | 额外索引实体描述 + 社区摘要 ~$0.02/篇 |
| **单篇总成本** | **~$0.02** | **~$0.08-0.18** | **~$0.35-0.85** |

（以 10 页研报、约 20 个 chunk 估算，使用 GPT-4o-mini 做抽取）

成本差异的根本原因：GraphRAG 把"理解文档"的工作从查询时前移到了索引时（社区检测+摘要生成），换来查询时更精准的全局召回。

成本 trade-off：

-   文档量小、查询量大 → GraphRAG 划算（索引成本摊薄）
-   文档量大、查询量小 → LightRAG 划算（避免高昂索引成本）
-   文档更新频繁 → LightRAG 划算（增量更新），GraphRAG 不划算（需重建社区）

#### 方案选择建议

推荐方案 A（LightRAG），理由：

1.  金融研报场景大部分查询是实体级别的（某公司某业务），LightRAG 双层检索足够覆盖
2.  研报持续入库，增量更新是刚需，GraphRAG 在这方面支持不足
3.  索引成本低 3-5 倍，对大量研报入库更友好
4.  如果后续发现全局概括类查询效果不够好，可以单独给 LightRAG 补一个轻量的"主题聚类+摘要"模块，不需要整体迁移到 GraphRAG

#### 切分层在 Graph RAG 中的角色

引入 Graph RAG 后，切分（保序极大团）和 PDF 清洗仍然保留，但角色从"生成高质量检索单元"变为"提供高质量的数据地基"。具体影响两个关键环节：

1. **抽取质量** — chunk 语义越完整，LLM 抽出的实体/关系越准。极大团保证团内句子两两内聚，一条完整的因果链（"A收购B → 导致C股价上涨"）大概率在同一个 chunk 里，抽取时不会断裂。如果切分质量差，关系被切到两个 chunk，这条关系就抽不出来
2. **溯源质量** — 检索命中实体后，最终送给 LLM 的还是 `source_chunk_id` 对应的原文 chunk。chunk 质量差（硬切、语义不完整），即使图谱检索精准，最后生成的回答也会缺上下文

普通 RAG 的文本检索路径（ES + 向量双路召回）可以去掉，LightRAG 内部已融合实体向量匹配（≈语义检索）。但表格的 BM25 + 向量检索和 Text-to-SQL 不受影响。

**降级兜底**：部分 chunk 可能抽不出有意义的实体/关系（如纯观点性文字"我们认为市场前景乐观"），这些 chunk 在图谱中没有对应节点，Graph RAG 检索不到。如果这类内容占比较高，可保留一条普通向量检索作为兜底，与图谱检索并行合并结果。

#### 整体流程简化

引入 Graph RAG 后，整体数据流非常简洁：

```
PDF → 清洗（已有）→ 切分（已有）→ LLM 实体/关系抽取（新增）→ 图谱建好
                                                              ↓
                                    LightRAG.query() / GraphRAG API 搞定检索
```

- LightRAG 不需要单独生成摘要，抽完实体/关系直接建图即可
- GraphRAG 才需要额外的社区摘要生成步骤
- 表格和结构化数据的检索路径不走 Graph RAG（表格→BM25+向量，数值→Text-to-SQL）
- 新增的开发量核心就一块：**LLM 实体/关系抽取 + 入图**，检索侧直接调 LightRAG API，不用自己写检索逻辑

#### 检索参数调优

Graph RAG 的检索参数与传统向量库不同。传统向量库调的是索引结构参数（nprobe、ef_search、相似度阈值），本质是"精度 vs 速度"的平衡。Graph RAG 调的是检索语义参数：

| 参数 | 说明 | 影响 |
|------|------|------|
| 检索模式 | LightRAG 的 low-level / high-level / hybrid | 决定走精确实体匹配还是主题概念匹配 |
| top-K 实体/关系 | 向量匹配后取多少个实体 | 太少漏召回，太多引入噪声 |
| 溯源 chunk 数 | 每个命中实体回溯多少个 source_chunk | 影响送给 LLM 的上下文量 |
| 子图扩展跳数（仅 GraphRAG） | 1跳 / 2跳 / 3跳 | 跳数越多关联越远，但噪声也越大 |
| 社区层级（仅 GraphRAG） | 查哪一层的社区摘要 | 底层细粒度，高层更概括 |

**实际上大部分参数不需要手动调**。LightRAG 直接用 `hybrid` 模式，自动同时走低层级 + 高层级，top-K 和相似度阈值有合理默认值，开箱即用。

正常开发流程：**hybrid 模式上线 → 收集 bad case → 针对性微调**，不用提前纠结参数。只在效果不达预期时作为排查手段：
- 召回太少 → 放大 top-K
- 噪声太多 → 收紧相似度阈值
- 全局概括类回答太泛 → 调整溯源 chunk 数

这跟向量库调参性质不同——向量库的 nprobe/ef_search 几乎每个项目都要调，Graph RAG 这些参数默认值通常够用。

### 10.2 数据处理

#### 10.2.1 实体/关系抽取（两方案共用）

从每个 chunk 中用 LLM 提取结构化三元组 `(实体A, 关系, 实体B)`，将非结构化文本转化为图谱节点和边。这一步两方案共用，差异在抽取粒度。

抽取示例：

```
chunk: "腾讯2024年Q3游戏业务海外营收同比增长15%，主要受益于《VALORANT》在东南亚市场的强劲表现"

抽取结果：
(腾讯, 拥有业务, 游戏业务)
(腾讯游戏业务, 海外营收同比增长, 15%)
(VALORANT, 驱动增长, 腾讯游戏海外营收)
(VALORANT, 市场表现强劲, 东南亚市场)
```

双方案抽取差异：

| 维度 | 方案 A：LightRAG | 方案 B：GraphRAG |
| --- | --- | --- |
| 抽取输出 | (head, relation, tail, description) 四元组 | (head, relation, tail, description) + 实体类型标注（公司/人物/指标/事件） |
| 实体去重 | 基础去重（同名合并） | 更严格的 entity resolution（"腾讯""腾讯控股""0700.HK"合并为同一实体） |
| Prompt 模板 | LightRAG 内置 prompt，直接调用 | 需自定义 prompt，额外要求识别实体类型和层级关系 |
| 单篇抽取成本 | ~$0.05-0.15 | ~$0.10-0.30（prompt 更长，输出更多） |

抽取质量关键点（两方案共同）：

-   金融术语的关系粒度——"受益于"和"得益于"是否合并为同一关系类型
-   数值归属——"15%"要挂到正确的实体和时间维度上
-   否定/条件关系——"如果宏观环境恶化，可能影响..."不能抽成确定性关系

#### 10.2.2 图谱构建（两方案分叉点）

实体抽取之后，两方案的处理流程开始分叉：

**方案 A：LightRAG — 直接建图 + embedding**

```
实体/关系抽取结果
  │
  ├── 实体去重合并（同名合并）
  ├── 构建图谱（NetworkX / Neo4j）
  ├── 对实体描述做 embedding → 向量索引
  └── 对关系描述做 embedding → 向量索引

  完成，可直接查询
```

**方案 B：GraphRAG — 建图 + 社区检测 + 摘要生成**

```
实体/关系抽取结果
  │
  ├── 实体去重合并（严格 entity resolution）
  ├── 构建图谱（NetworkX / Neo4j）
  │
  ├── 【额外步骤1】Leiden 社区检测
  │   ├── 对图谱做社区聚类，把紧密关联的实体聚成社区
  │   ├── 多层级社区（大社区包含小社区）
  │   └── 输出：社区 ID → 实体列表 的映射
  │
  ├── 【额外步骤2】社区摘要生成
  │   ├── 对每个社区，收集其包含的所有实体和关系
  │   ├── 用 LLM 生成社区摘要（"这个社区主要描述了..."）
  │   ├── 多层级摘要：底层社区摘要 → 上层社区摘要
  │   └── 这是成本增加的主要来源（~$0.20-0.50/篇）
  │
  ├── 对实体描述做 embedding → 向量索引
  ├── 对关系描述做 embedding → 向量索引
  └── 【额外】对社区摘要做 embedding → 向量索引

  完成，可查询
```

#### 10.2.3 图谱存储结构

映射关系存在图谱侧，chunk 本身零侵入：

```json
// chunk 侧（不变，两方案共用）
{
  "chunk_id": "c_0042",
  "meta": "腾讯2024年报 | 游戏业务",
  "content": "原文...",
  "embedding": [...]
}

// 图谱节点（两方案共用）
{
  "entity_id": "腾讯控股",
  "type": "公司",
  "description": "中国互联网科技公司，主营游戏、社交...",
  "source_chunks": ["c_0042", "c_0078", "c_0156"],
  "description_embedding": [...]
}

// 图谱边（两方案共用）
{
  "source": "腾讯控股",
  "target": "VALORANT",
  "relation": "运营游戏",
  "description": "腾讯旗下拳头游戏开发运营的FPS游戏",
  "source_chunks": ["c_0042"],
  "weight": 3
}

// 社区节点（仅 GraphRAG 方案 B）
{
  "community_id": "comm_012",
  "level": 1,
  "entities": ["腾讯控股", "VALORANT", "拳头游戏", "东南亚市场"],
  "summary": "该社区围绕腾讯的游戏业务海外布局，核心实体包括腾讯控股及其旗下拳头游戏开发的VALORANT，主要市场为东南亚地区...",
  "summary_embedding": [...],
  "parent_community": "comm_003"
}
```

#### 10.2.4 超级节点处理

典型金融图谱节点度数呈幂律分布：90% 节点度数 <10，2% 节点度数 >100（大公司、高频术语）。

| 方案 | 超级节点影响 | 处理方式 |
| --- | --- | --- |
| 方案 A：LightRAG | 影响小——检索机制是向量匹配，不是图遍历，节点度数不影响检索性能 | 天然缓解 |
| 方案 B：GraphRAG | 影响社区检测质量——超级节点可能导致社区过大或社区边界不合理 | 需在社区检测前做预处理（拆分或降权） |

通用补充方案（两方案均适用于需要显式多跳遍历的场景）：

1.  **关系类型分桶**：查询时只遍历特定类型的边，O(所有边) → O(特定类型边)
2.  **扇出限制**：每个节点最多扩展 top-K 邻居（按 weight 排序）
3.  **实体细粒度拆分**：抽取时保留细粒度实体（"腾讯游戏业务"而非"腾讯"），自然降低单节点度数

#### 10.2.5 增量更新处理

| 维度 | 方案 A：LightRAG | 方案 B：GraphRAG |
| --- | --- | --- |
| 新文档入库 | 直接抽取实体/关系 → 合并到已有图谱 → 更新 embedding 索引 | 抽取实体/关系 → 合并到已有图谱 → 需重跑社区检测 → 重新生成受影响社区的摘要 |
| 实体合并 | 新实体与已有实体同名则合并，更新 description | 同左，但还需判断合并后是否影响社区边界 |
| 索引更新 | 增量更新实体/关系的 embedding | 增量更新实体/关系 embedding + 重新生成受影响社区摘要的 embedding |
| 复杂度 | 低，O(新文档实体数) | 高，最坏情况需全量重建社区（O(全图实体数)） |
| 实现现状 | LightRAG 原生支持 | GraphRAG 官方增量支持不完善，需自行实现局部社区更新 |

### 10.3 核心流程

#### 10.3.1 索引流程（两方案对比）

共用部分（PDF 清洗 + 切分）：

```
PDF 原文
  │
  ▼
┌─────────────────────────────────────────────────────┐
│  PDF 清洗层（已有，不变）                              │
│  pdf_parser/pdf_parsing_optimized.py                 │
│  PDFParser.process_text()                            │
└──────────────────────┬──────────────────────────────┘
                       │
                       ▼
┌─────────────────────────────────────────────────────┐
│  句子切分 + 语义切分（已有，不变）                      │
│  topic_method/topic_segmentation.py                  │
│  cut_sentences() → find_cliques_recursive()          │
│                                                      │
│  输出：chunk list（带 meta + content）                │
└──────────────────────┬──────────────────────────────┘
                       │
          ┌────────────┴────────────┐
          ▼                         ▼
┌──────────────────┐    ┌──────────────────────────────┐
│  chunk 入库       │    │  实体/关系抽取（新增）         │
│  （已有，不变）    │    │  LLM few-shot 抽取            │
│                   │    │  chunk → (head, rel, tail)    │
│  向量库存储：      │    │  实体去重合并                  │
│  {                │    │                               │
│    chunk_id,      │    │  ┌─── 方案分叉 ───┐           │
│    meta,          │    │  ▼               ▼           │
│    content,       │    │  方案A          方案B         │
│    embedding      │    │  LightRAG      GraphRAG      │
│  }                │    │                               │
│                   │    └───────────────────────────────┘
│  用途：            │
│  表格BM25+向量    │
│  召回走这条路   │
└──────────────────┘
```

**方案 A：LightRAG 索引流程**

```
实体/关系抽取结果
  │
  ▼
┌─────────────────────────────────────────────────────┐
│  构建图谱                                            │
│  NetworkX / Neo4j                                    │
│                                                      │
│  图谱存储：                                           │
│  ├── 节点：entity_id, type, description,             │
│  │         source_chunks                             │
│  └── 边：source, target, relation,                   │
│          source_chunks, weight                       │
└──────────────────────┬──────────────────────────────┘
                       │
                       ▼
┌─────────────────────────────────────────────────────┐
│  向量索引                                            │
│  ├── 实体描述 embedding                              │
│  └── 关系描述 embedding                              │
└─────────────────────────────────────────────────────┘

  索引完成，可直接查询
```

**方案 B：GraphRAG 索引流程**

```
实体/关系抽取结果
  │
  ▼
┌─────────────────────────────────────────────────────┐
│  构建图谱（同方案 A）                                 │
│  NetworkX / Neo4j                                    │
│                                                      │
│  图谱存储：                                           │
│  ├── 节点：entity_id, type, description,             │
│  │         source_chunks                             │
│  └── 边：source, target, relation,                   │
│          source_chunks, weight                       │
└──────────────────────┬──────────────────────────────┘
                       │
                       ▼
┌─────────────────────────────────────────────────────┐
│  【额外】Leiden 社区检测                              │
│  ├── 对图谱做社区聚类                                │
│  ├── 多层级社区（大社区包含小社区）                    │
│  └── 输出：community_id → [entity_list] 映射         │
└──────────────────────┬──────────────────────────────┘
                       │
                       ▼
┌─────────────────────────────────────────────────────┐
│  【额外】社区摘要生成                                 │
│  ├── 收集每个社区的实体和关系                         │
│  ├── LLM 生成社区摘要                                │
│  ├── 多层级：底层社区摘要 → 上层社区摘要              │
│  └── 存储：community_id, level, entities,            │
│            summary, parent_community                 │
└──────────────────────┬──────────────────────────────┘
                       │
                       ▼
┌─────────────────────────────────────────────────────┐
│  向量索引                                            │
│  ├── 实体描述 embedding                              │
│  ├── 关系描述 embedding                              │
│  └── 【额外】社区摘要 embedding                      │
└─────────────────────────────────────────────────────┘

  索引完成，可查询
```

#### 10.3.2 检索流程（两方案对比）

**方案 A：LightRAG 检索流程**

```
用户查询
  │
  ▼
查询路由（Agent / 分类器）
  │
  ├── 文本类问题 ──→ LightRAG.query()
  │   ├── 低层级：实体/关系描述 向量匹配
  │   ├── 高层级：主题/概念 向量匹配
  │   ├── 命中实体/关系 → 取 source_chunk_id
  │   └── 回 chunk 库取原文 → 送 LLM
  │
  ├── 表格类问题 ──→ BM25 + 向量双路召回（已有）
  │   └── 命中后取完整原始表格 → 送 LLM
  │
  └── 精确数值 ──→ Text-to-SQL（已有）
      └── SQL 查询结果 → 送 LLM
  │
  ▼
合并去重 + Reranker 精排
  ▼
top-K 结果 + 图谱三元组 → LLM 生成回答
```

**方案 B：GraphRAG 检索流程**

```
用户查询
  │
  ▼
查询路由（Agent / 分类器）— 路由粒度更细
  │
  ├── 文本类问题（全局概括）──→ 社区摘要匹配
  │   ├── 查询 embedding 与社区摘要 embedding 匹配
  │   ├── 命中社区摘要 → 直接作为上下文
  │   ├── 可选：取社区内实体的 source_chunk_id → 补充原文
  │   └── 适合："行业整体趋势""所有公司共同风险"
  │
  ├── 文本类问题（局部精确）──→ 实体/关系匹配
  │   ├── 实体向量匹配 → 定位查询实体
  │   ├── 子图提取：沿关系边扩展 1-3 跳
  │   ├── 命中实体/关系 → 取 source_chunk_id
  │   └── 回 chunk 库取原文 → 送 LLM
  │
  ├── 表格类问题 ──→ BM25 + 向量双路召回（已有）
  │   └── 命中后取完整原始表格 → 送 LLM
  │
  └── 精确数值 ──→ Text-to-SQL（已有）
      └── SQL 查询结果 → 送 LLM
  │
  ▼
合并去重 + Reranker 精排
  ▼
top-K 结果 + 社区摘要/图谱三元组 → LLM 生成回答
```

#### 10.3.3 查询路由扩展（两方案对比）

**方案 A：LightRAG 路由**

路由简单，文本类统一走 LightRAG.query()，内部自动处理低层级/高层级检索：

| 信号 | 路由方向 | 示例 |
| --- | --- | --- |
| 关系词（供应商、客户、竞争对手、子公司） | LightRAG | "A的供应商" |
| 比较词（对比、区别、相比） | LightRAG | "A和B的区别" |
| 因果词（为什么、导致、受益于） | LightRAG | "什么导致了下跌" |
| 纯观点/趋势类 | LightRAG | "前景如何" |
| 全局概括类 | LightRAG（高层级检索） | "行业整体趋势" |
| 表格相关（营收表、分业务数据） | BM25 + 向量 | "XX公司营收表" |
| 精确数值（多少、增长率） | Text-to-SQL | "营收多少" |

**方案 B：GraphRAG 路由**

路由更细，文本类需进一步区分全局查询和局部查询：

| 信号 | 路由方向 | 示例 |
| --- | --- | --- |
| 全局概括（整体趋势、共同特征、行业概览） | 社区摘要匹配 | "中国互联网行业整体趋势" |
| 跨实体聚合（所有XX、哪些公司） | 社区摘要匹配 | "所有被调研公司的共同风险" |
| 关系词（供应商、客户、竞争对手） | 实体匹配 + 子图遍历 | "A的供应商" |
| 比较词（对比、区别、相比） | 实体匹配 + 子图遍历 | "A和B的区别" |
| 因果词（为什么、导致、受益于） | 实体匹配 + 子图遍历 | "什么导致了下跌" |
| 纯观点/趋势类（单实体） | 实体匹配 | "前景如何" |
| 表格相关 | BM25 + 向量 | "XX公司营收表" |
| 精确数值 | Text-to-SQL | "营收多少" |

实现建议：

-   方案 A：规则优先（关键词/正则初筛，覆盖 70-80%），积累 bad case 后再考虑 LLM 路由
-   方案 B：建议 LLM 路由（GPT-4o-mini），因为全局/局部的区分靠规则难以准确判断，需要语义理解

### 10.4 三路召回架构（生产推荐）

基于前面的分析，金融 Agent 的生产环境推荐采用三路召回架构：ES + 向量RAG + GraphRAG。

#### 10.4.1 架构设计

```
用户查询
   │
   ├─→ ES（关键词/BM25 + 过滤聚合）
   │     精确匹配、时间过滤、字段筛选
   │     "2024年Q3 腾讯 营收"
   │
   ├─→ 向量RAG（语义检索）
   │     模糊语义匹配、相似问题召回
   │     "游戏行业最近监管政策怎么样"
   │
   └─→ GraphRAG（社区摘要 + 图遍历）
         产业链、因果链、全局模式
         "光伏上下游关系" "猪周期影响哪些板块"
```

#### 10.4.2 各路分工

| 路径 | 擅长 | 典型查询 |
|------|------|----------|
| ES | 精确匹配、结构化过滤、实时性 | "贵州茅台 2024年报"、股票代码搜索、时间范围过滤 |
| 向量RAG | 语义泛化、同义词容错 | "白酒龙头业绩怎么样"（不提茅台也能命中） |
| GraphRAG | 关系发现、跨文档归纳、全局概括 | "消费电子产业链全景"、"历史上加息周期银行表现" |

**GraphRAG 在三路架构中的独特价值**：它能回答"为什么"和"怎么关联的"，这是 ES 和向量RAG 做不到的。但它不能回答"现在多少钱"或"精确算一下 PE"。

#### 10.4.3 路由策略

```
查询进来
   │
   ▼
路由判断（Agent / 分类器 / 规则）
   │
   ├── 包含明确实体 + 时间 → ES 优先
   │     "腾讯 2024Q3 营收"
   │
   ├── 开放性语义问题 → 向量RAG
   │     "白酒行业前景如何"
   │
   ├── 涉及"产业链/板块/历史规律/影响/关联" → GraphRAG
   │     "光伏产业链上下游"
   │     "猪周期影响哪些板块"
   │
   └── 问题模糊 → 多路并发，结果合并
```

**结果融合**：
- 简单场景：取 top-k 合并去重
- 复杂场景：三路结果都扔给 LLM，让它综合判断

#### 10.4.4 索引共建策略

同一份研报入库时，三路索引可以共享前置处理：

```
PDF 原文
   │
   ▼
PDF 清洗 + 切分（共用）
   │
   ├─→ ES 存储
   │     原文 + 结构化字段（公司、时间、章节）
   │     实体抽取结果可回写 ES 做字段（方便按实体过滤）
   │
   ├─→ 向量库存储
   │     chunk embedding
   │
   └─→ GraphRAG 存储
         实体/关系抽取 → 图谱构建 → 社区检测 → 摘要生成
```

#### 10.4.5 工程复杂度分析

三路召回的工程成本不可忽视：

| 组件 | 要维护的东西 | 运维难度 |
|------|-------------|---------|
| ES | 集群部署、分片、索引模板、分词器调优 | 中 |
| 向量库 | Milvus/Qdrant/Pgvector、embedding 模型服务 | 中 |
| GraphRAG | 图数据库 + LLM 抽取 pipeline + 社区重建任务 | 高 |
| 数据同步 | 一份研报入三个库，保证一致性 | 高 |
| 融合层 | 路由逻辑、结果合并、降级策略 | 中 |

**实际问题**：
- 三倍入库成本：每份研报要跑三遍处理
- 三倍存储成本：同样的内容存三份不同形态
- 延迟叠加：三路并发查，最慢的那路决定整体延迟
- GraphRAG 的 LLM 成本：实体抽取 + 社区摘要，token 消耗大
- 调试复杂：结果不对时，要排查是哪路出了问题

#### 10.4.6 分阶段演进建议

不建议一上来就三路实时。推荐分阶段演进：

**阶段一：先跑通 ES + 向量RAG（双路）**

```
ES（精确匹配 + 过滤）
      +
向量RAG（语义召回）
```

这两个技术成熟、工具链完善，很多公司已经在用。先把这个跑稳。

**阶段二：GraphRAG 作为离线分析层，不参与实时召回**

```
实时查询 → ES + 向量RAG

离线任务 → GraphRAG 生成"产业链图谱"/"板块关联报告"
           结果存成静态文档，ES 可检索
```

把 GraphRAG 的产出当成一种"预生成的分析报告"，而不是实时召回源：
- 不用承担实时查询压力
- 社区摘要可以慢慢生成，一周更新一次
- 用户问产业链时，直接检索这些预生成的报告

**阶段三：真有需求再上三路实时**

等业务验证了 GraphRAG 的全局分析确实有价值，再投入做实时化：
- 把 GraphRAG 从离线改成准实时（增量社区更新）
- 三路并发查询 + 结果融合
- 完善降级和兜底策略

#### 10.4.7 降级与兜底策略

生产环境里 Graph RAG 不可能 100% 覆盖所有查询。需要明确的降级链路：

```
查询进来
   │
   ▼
GraphRAG 检索
   │
   ├── 命中实体/社区，置信度高 → 正常返回
   │
   ├── 命中但置信度低（向量距离远）→ 降级到向量RAG
   │   └── 用 chunk 的 embedding 做传统语义匹配
   │
   └── 完全未命中（图谱中无相关实体）→ 降级到 ES
       └── BM25 关键词检索
       └── 最后兜底：返回"未找到相关信息"，不要瞎编
```

这个降级链路在分阶段架构上实现很自然——ES 和向量RAG 本来就在线，GraphRAG 只是增量叠加，降级时直接走已有路径。

---

## 11. 参考资料

-   [Anthropic Contextual Retrieval](https://www.anthropic.com/news/contextual-retrieval)
-   [RAPTOR 论文](https://arxiv.org/abs/2401.18059)
-   [Dense-X Retrieval 论文](https://arxiv.org/abs/2312.06648)
-   [HyDE 论文](https://arxiv.org/abs/2212.10496)
-   [LangChain MultiVector Retriever](https://python.langchain.com/docs/how_to/multi_vector/)
-   [LlamaIndex Document Summary Index](https://docs.llamaindex.ai/en/stable/examples/index_structs/doc_summary/)
-   [GraphRAG](https://github.com/microsoft/graphrag)
-   [LightRAG](https://github.com/HKUDS/LightRAG)
-   [TARGET: Table Retrieval for Generative Tasks](https://arxiv.org/abs/2406.04473)
-   [TableRAG (NeurIPS 2024)](https://arxiv.org/abs/2410.04739)
-   [T2-RAGBench: 金融文本+表格混合问答评测](https://arxiv.org/abs/2501.13032)
-   [Table Meets LLM: Markdown vs HTML 结构理解评测 (WSDM 2024)](https://arxiv.org/abs/2305.13062)
-   [HtmlRAG: HTML is Better Than Plain Text for RAG (WWW 2025)](https://arxiv.org/abs/2411.02959)
-   [Tables as Texts or Images: 表格格式对 LLM 推理的影响 (ACL 2024)](https://arxiv.org/abs/2402.12424)
-   [TAP4LLM: 表格序列化策略对比](https://arxiv.org/abs/2312.09039)